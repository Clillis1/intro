{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another introduction to FFTs, leading to a discussion of noise\n",
    "\n",
    "Each cell in this notebook needs to be executed in sequence. We begin by importing the libraries that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to generate some arrays of samples, and see what happens when we calculate their FFTs.\n",
    "\n",
    "Incidentally, the first \"F\" in \"FFT\" stands for \"Fast\", and this is because it is calculated using an algorithm published in 1965 by Cooley and Tukey. The algorithm reduces the time required to calculate the Fourier transform by realising that many of the terms are duplicated. It is $O(N\\log N)$ rather than $O(N^2)$, so it becomes increasingly valuable for large numbers of samples. The Cooley-Tukey algorithm works best for sample sizes that are a power of two, so it can be an advantage to pad your samples with zeros up to the next power of two. The algorithm works worst for a prime number of samples.\n",
    "\n",
    "Anyway... back to our explorations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose a nice large number of samples, and make it\n",
    "# a power of 2, which is ideal for the FFT algorithm.\n",
    "\n",
    "numSamples = 2**10\n",
    "\n",
    "# Set the time between samples in seconds to 0.001 second. This \n",
    "# give us a Nyquist frequency (the highest frequency we can sample\n",
    "# without aliasing) of 500 Hz.\n",
    "\n",
    "dt = 0.001\n",
    "\n",
    "# Now generate an array of times, beginning at zero, separated by dt.\n",
    "\n",
    "t = np.linspace(0, dt * (numSamples - 1), numSamples)\n",
    "\n",
    "# In Fourier space, this array of times corresponds to an array of\n",
    "# frequencies, so lets calculate that.\n",
    "\n",
    "f = np.fft.fftfreq(t.size, dt)\n",
    "\n",
    "# Ok, so we are now ready to create a signal. Let's try a sine wave\n",
    "# at 400 Hz.\n",
    "\n",
    "freqHz = 400.0\n",
    "y = np.sin(2 * np.pi * freqHz * t)\n",
    "\n",
    "# Now find the FFT of the signal, and plot its absolute value versus frequency.\n",
    "\n",
    "fft = np.fft.fft(y)\n",
    "plt.plot(f, abs(fft))\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how you get +ve and -ve frequencies. The negative frequencies are only relevant for complex input signals, and since we will almost always be dealing with real input signals (i.e., from measurements of voltages, currents, etc), we can ignore the negative frequencies, and just plot the +ve ones as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The +ve frequencies are in the first half of the FFT arrays.\n",
    "# Note that we use integer division to find the correct array slice endpoint.\n",
    "\n",
    "plt.plot(f[:numSamples//2], abs(fft[:numSamples//2]), '.')\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But a simpler approach is to use the numpy routines `rfft` and `rfftfreq` that are specifically designed for real samples, and return only the positive frequencies. We also multiply the FFT by $2/n$ where $n$ is the number of samples, so that the amplitude is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the frequency bins. Note that we are calling rfftfreq, for real samples.\n",
    "\n",
    "f = np.fft.rfftfreq(t.size, dt)\n",
    "\n",
    "# Now find the FFT of the signal using rfft, normalise by multiplying by\n",
    "# 2/numSamples, and plot the absolute value versus frequency.\n",
    "\n",
    "fft = np.fft.rfft(y) * 2 / numSamples\n",
    "plt.plot(f, abs(fft), 'o')\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wonder why there is a *distribution* of frequencies in the FFT, whereas we created the signal from a pure sine wave. The reason is that the FFT assumes that the input signal is *periodic*, so even though we only provided 1024 samples, the FFT assumes that the signal continues forever, and is constructed by taking copies of the 1024 samples and adding them to the end of our original 1024, and so on. Unless we choose the input frequency very carefully, there will be a discontinuity at the join, and the FFT will find a range of sine waves that do good job of trying to follow the discontinuity.\n",
    "\n",
    "The spilling of power into neighbouring frequencies is an example of *spectral leakage*. There is not much you can do about it when using a FFT. Sampling the input waveform more frequently doesn't help. What does help is to increase the observation time, and in the limit that you sample for infinity seconds, you get a perfect result!\n",
    "\n",
    "To explore this further, let's choose a frequency near 400 Hz that gives an exact integer number of sine waves in 1024 samples at 0.001 second per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose a frequency to fit an integral number of cycles in 1024 samples.\n",
    "\n",
    "freqHz = 410 / (1024 * 0.001)\n",
    "print(\"the frequency is\", freqHz, \"Hz\")\n",
    "\n",
    "# Create the signal.\n",
    "\n",
    "y = np.sin(2 * np.pi * freqHz * t)\n",
    "f = np.fft.rfftfreq(t.size, dt)\n",
    "\n",
    "# Calculate the FFT and plot it.\n",
    "\n",
    "fft = np.fft.rfft(y) * 2 / numSamples\n",
    "\n",
    "plt.plot(f, abs(fft))\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.show()\n",
    "\n",
    "# Plot it again, this time zooming in on the relevant section.\n",
    "\n",
    "plt.plot(f, abs(fft), 'o')\n",
    "plt.xlim(390, 410)\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that all the power is now at a single frequency, since the infinite repetition of our samples has no discontinuities.\n",
    "\n",
    "# Power spectrum\n",
    "\n",
    "For many purposes it is more useful to plot the *power spectrum* rather than the amplitude spectrum (i.e., the absolute value of the FFT). Since power goes as the square of the amplitude, the power spectrum simply comes from squaring the absolute value of the FFT, or equivalently, multiplying the FFT by its complex conjugate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the power spectrum, i.e., the square of the absolute value of the FFT.\n",
    "\n",
    "plt.plot(f, abs(fft) ** 2)\n",
    "plt.ylabel(\"Power\")\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.show()\n",
    "\n",
    "# We get the same result by multiplying the FFT by its complex\n",
    "# conjugate. We take the real part to stop plot() from complaining -\n",
    "# the imaginary part should be all zeros anyway.\n",
    "\n",
    "plt.plot(f, np.real(fft * np.conj(fft)))\n",
    "plt.ylabel(\"Power\")\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do the real and imaginary parts of the FFT mean?\n",
    "\n",
    "So far we have been plotting the absolute value of the FFT. The absolute value tells us the how much of a particular frequency is in the input array. It tells us nothing about the phase relationship between the frequencies; very different waveforms can be produced by shifting the phases of the frequencies. For example, the following snippet generates four input waveforms that have identical absolute values of their FFTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqHz = 5 / (1024 * 0.001)\n",
    "print(\"the frequency is\", freqHz, \"Hz\")\n",
    "\n",
    "# Create four signals, with the same frequencies and amplitudes, \n",
    "# but different phases. We displace them in the y direction to\n",
    "# make them easy to see.\n",
    "\n",
    "y0 = np.sin(2 * np.pi * freqHz * t) + 0.3 * np.sin(2 * np.pi * (freqHz + freqHz) * t)\n",
    "y1 = np.cos(2 * np.pi * freqHz * t) + 0.3 * np.sin(2 * np.pi * (freqHz + freqHz) * t)\n",
    "y2 = np.sin(2 * np.pi * freqHz * t) + 0.3 * np.cos(2 * np.pi * (freqHz + freqHz) * t)\n",
    "y3 = np.cos(2 * np.pi * freqHz * t) + 0.3 * np.cos(2 * np.pi * (freqHz + freqHz) * t)\n",
    "\n",
    "plt.plot(y0 - 3.0)\n",
    "plt.plot(y1 - 1.0)\n",
    "plt.plot(y2 + 1.0)\n",
    "plt.plot(y3 + 3.0)\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets plot the absolute value, argument, real, and imaginary parts of the FFT for each of these signals. I have only shown y0 in this notebook, you need to edit this to explore y1, y2, and y3.\n",
    "\n",
    "You need to look at the plots very carefully. The argument plot looks chaotic, but that is simply because the real and imaginary components are at the level of floating-ppint noise apart from at the two input frequencies (4.88 Hz and 2 * 4.88 Hz) - so only look at the values at these two points. Also, keep an eye on the scaling factor to be applied to the y-axis.\n",
    "\n",
    "With some careful study you should see the following:\n",
    "\n",
    "- the absolute value plot is the same for all four signals\n",
    "- the argument plot shows the phase relationship of the component frequencies\n",
    "- the real plot shows the cosine component\n",
    "- the imaginary plot shows minus the sine component\n",
    "\n",
    "The important thing to take away from this is that there is nothing mysterious about the complex nature of the FFT. It is simply that you need two numbers (amplitude and phase) to represent a frequency component in a signal, and the easiest way to do this is using complex numbers. In particular, there is nothing strange of mysterious about the *imaginary* component of an FFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotFFT(y):\n",
    "\n",
    "    # Calculate the FFT, normalise it, then plot.\n",
    "    \n",
    "    fft = np.fft.rfft(y) * 2 / numSamples\n",
    "\n",
    "    plt.plot(f, abs(fft), 'o')\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Absolute value of FFT\")\n",
    "    plt.xlim(0,20)\n",
    "    plt.show()\n",
    "\n",
    "# Plot it again, this time zooming in on the relevant section.\n",
    "\n",
    "    plt.plot(f, np.angle(fft), 'o')\n",
    "    plt.xlim(0, 20)\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Arg of FFT\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(f, np.real(fft), 'o')\n",
    "    plt.xlim(0, 20)\n",
    "    plt.ylabel(\"Real value of FFT\")\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(f, np.imag(fft), 'o')\n",
    "    plt.xlim(0, 20)\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Imaginary value of FFT\")\n",
    "    plt.show()\n",
    "\n",
    "# Now actually plot a signal! You should edit y0 to be y1, y2, and then y3, and\n",
    "# examine the differences.\n",
    "\n",
    "plotFFT(y0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise\n",
    "\n",
    "The above discussion has concentrated on examining clear sinusoidal signals, but what happens if the samples are noisy?\n",
    "\n",
    "## White noise\n",
    "\n",
    "Let's begin with two sine-waves (chosen to have an integral number of cycles in our sample window) with some Gaussian noise added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose a couple of frequencies, one low, one high.\n",
    "\n",
    "freq1Hz = 5 / (1024 * 0.001)\n",
    "print(\"the 1st frequency is\", freq1Hz, \"Hz\")\n",
    "\n",
    "freq2Hz = 410 / (1024 * 0.001)\n",
    "print(\"the 2nd frequency is\", freq2Hz, \"Hz\")\n",
    "\n",
    "# Create the samples.\n",
    "\n",
    "y = np.sin(2 * np.pi * freq1Hz * t) + np.sin(2 * np.pi * freq2Hz * t) + 2.0 * np.random.randn(numSamples) \n",
    "\n",
    "# And plot them.\n",
    "\n",
    "plt.plot(t, y)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the FFT, and plot its power spectrum.\n",
    "\n",
    "fft = np.fft.rfft(y) * 2 / numSamples\n",
    "plt.plot(f, abs(fft) ** 2, '.')\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the two signal frequencies are clearly detected (although their power isn't exactly 1.0), and the noise appears with roughly equal amplitude at all frequencies.\n",
    "\n",
    "If we average the amplitude spectrum from many random samples, the noise frequency spectrum becomes clearer. Try the following code snippet with various values of $n$. Note the scaling on the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotAverageFFT(n):\n",
    "    numSamples = 1024\n",
    "    dt = 0.001\n",
    "    t = np.linspace(0, dt * (numSamples - 1), numSamples)\n",
    "    f = np.fft.rfftfreq(t.size, dt)\n",
    "    \n",
    "    # We are going to calculate an average power spectrum,\n",
    "    # so we begin by zeroing a suitable array.\n",
    "    \n",
    "    powerSpectrum = np.zeros(f.size)\n",
    "\n",
    "    # Now sum n power spectra. \n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        # Uncomment this line for Gaussian distributed samples.\n",
    "        \n",
    "        y = np.random.randn(numSamples)\n",
    "        \n",
    "        # Uncomment this line for uniform distrubuted samples.\n",
    "        \n",
    "        #y = np.random.random(numSamples) - 0.5\n",
    "        \n",
    "        powerSpectrum += abs(np.fft.rfft(y) * 2 / numSamples) ** 2\n",
    "        \n",
    "    # And divide by n to make the avergage.\n",
    "    \n",
    "    powerSpectrum /= n\n",
    "\n",
    "    plt.plot(f, powerSpectrum)\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.show()\n",
    "\n",
    "plotAverageFFT(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the above plots that the noise we added has a constant power for all frequencies, where the power is measured in bins of constant width (in Hz). This is called *white noise*. Note that the fact that we used a Gaussian distribution of sample values at each point isn't important - all that matters for noise to be white is that there is *no correlation* from one sample to the next.\n",
    "\n",
    "With white noise there is as much noise in the bin from 1-2 Hz as there is from 1,000,000-1,000,001 Hz.\n",
    "\n",
    "## 1/f noise (pink noise)\n",
    "\n",
    "In many physical systems, the noise isn't white, but increases to lower frequencies as $1/f$. This is called $1/f$ noise, or sometimes *pink noise*. With $1/f$ noise there is equal power in logarithmic space, e.g., the noise power from 1-10 Hz is the same as from 1,000-10,000 Hz.\n",
    "\n",
    "Generating pink noise in a computer is a little trickier than white noise. One algorithm for doing it, approximately, is the Voss-McCartney algorithm. I won't explain how this works, but let's try it and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def voss(nrows, ncols=16):\n",
    "    \n",
    "    # From Allen Downey, Think DSP\n",
    "    \n",
    "    \"\"\"Generates pink noise using the Voss-McCartney algorithm.\n",
    "    \n",
    "    nrows: number of values to generate\n",
    "    rcols: number of random sources to add\n",
    "    \n",
    "    returns: NumPy array\n",
    "    \"\"\"\n",
    "    array = np.empty((nrows, ncols))\n",
    "    array.fill(np.nan)\n",
    "    array[0, :] = np.random.random(ncols)\n",
    "    array[:, 0] = np.random.random(nrows)\n",
    "    \n",
    "    # the total number of changes is nrows\n",
    "    n = nrows\n",
    "    cols = np.random.geometric(0.5, n)\n",
    "    cols[cols >= ncols] = 0\n",
    "    rows = np.random.randint(nrows, size=n)\n",
    "    array[rows, cols] = np.random.random(n)\n",
    "\n",
    "    df = pd.DataFrame(array)\n",
    "    df.fillna(method='ffill', axis=0, inplace=True)\n",
    "    total = df.sum(axis=1)\n",
    "\n",
    "    return total.values\n",
    "\n",
    "def plotAverageFFT(n):\n",
    "    numSamples = 1024\n",
    "    dt = 0.001\n",
    "    t = np.linspace(0, dt * (numSamples - 1), numSamples)\n",
    "    f = np.fft.rfftfreq(t.size, dt)\n",
    "    \n",
    "    # As before, let's calculate the average power spectrum for a number\n",
    "    # of samples.\n",
    "    \n",
    "    powerSpectrum = np.zeros(f.size)\n",
    "\n",
    "    for i in range(n):\n",
    "        y = voss(numSamples) \n",
    "        powerSpectrum += abs(np.fft.rfft(y) * 2 / numSamples) ** 2\n",
    "\n",
    "    powerSpectrum /= n\n",
    "    \n",
    "    # Plot with linear axes.\n",
    "    \n",
    "    plt.plot(f, powerSpectrum)\n",
    "    plt.ylim(0.0,0.1)\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.show()\n",
    "    \n",
    "    # A log-log plot shows the noise spectrum more clearly.\n",
    "    \n",
    "    plt.plot(f, powerSpectrum)\n",
    "    plt.loglog()\n",
    "    plt.ylim(0.0001,1)\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.show()\n",
    "\n",
    "plotAverageFFT(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how the noise follows a $1/f$ power spectrum - the slope is $-1$ in the log-log plot. Also note that the slope isn't perfect. I don't know if this is a limitation of the Voss-McCartney algorithm, or the finite length of time over which the noise is sampled.\n",
    "\n",
    "## $1/f^2$ red noise\n",
    "\n",
    "If the power spectrum slope goes as $1/f^2$ the noise is referred to as red noise, or sometimes brown noise (the \"brown\" comes from \"Brownian motion\", which generates this type of noise).\n",
    "\n",
    "# Physical reasons for noise\n",
    "\n",
    "## Shot noise (also known as photon noise, Poisson noise, or Schottky noise)\n",
    "\n",
    "If the phenomenon under observation is inherently quantised (e.g., radioactive decay, the arrival of photons, the current due to electrons, rain drops on a roof), then Poissonion statistics gives the distribution of samples. \n",
    "\n",
    "The standard deviation of the samples in a Poisson distribution is given by $\\sqrt N$ where $N$ is the number of samples. The signal-to-noise ratio is therefore ${\\rm SNR}=N/\\sqrt N=\\sqrt N$, from which it is clear that shot noise only tents to be important when $N$ is small, so that the individual photons/electroncs/etc can be readily detected. At large values of $N$, other sources of noise will dominate.\n",
    "\n",
    "Shot noise is an example of white noise, i.e., it has a constant power per Hz at all frequencies.\n",
    "\n",
    "If you consider the flow of electron current in a wire, the mean square of the current noise is given by\n",
    "\n",
    "$$\\langle I^2_\\hbox{noise}\\rangle=2q\\langle I\\rangle\\Delta f$$\n",
    "\n",
    "where $q$ is the charge of an electron, $I$ is the current, and $\\Delta f$ is the bandwidth of the measurement in Hz.\n",
    "\n",
    "\n",
    "## Johnson noise (also known as thermal noise, or Nyquist noise)\n",
    "\n",
    "Even if no net current is flowing in a wire, there will still be electrons randomly moving backwards and forwards along the wire as a result of their thermal velocity. This produces a current noise known as Johnson noise. It is normally expressed as the voltage developed across the wire's resistance:\n",
    "\n",
    "$$\\langle V^2_\\hbox{noise}\\rangle=4kTR\\Delta f$$\n",
    "\n",
    "where $k$ is Boltzman's constant, $T$ is the temperature of the resistor, $R$ its resistance, and $\\Delta f$ is again the bandwidth of the measurement in Hz. Note that Johnson noise is independent of the current flow - the same amount of Johnson noise is superimposed on whatever DC current is flowing. Johnson noise provides a lower limit on the noise from a resistor; as the current increases, shot noise (and $1/f$ noise, see below) will kick in.\n",
    "\n",
    "Like shot noise, Johnson noise is an example of white noise.\n",
    "\n",
    "## $1/f$ noise (also known as flicker noise, or switching noise)\n",
    "\n",
    "Many physical systems exhibit $1/f$ noise, and the reasons are many and varied, and not always obvious.\n",
    "\n",
    "In the case of current flow through conductors, $1/f$ noise appears to result from fluctuations in *conductivity* due to thermal activation/deactivation of defects in the conductor.\n",
    "\n",
    "In a perfect world a conductor would be perfect metal lattice, and electrons would flow smoothly. In reality, the lattices contain *defects* such as missing atoms, dopant atoms, grain boundaries, and so on. These defects act to scatter electrons, and hence reduce the conductivity. Furthermore, the defects can be in various states depending on temperature, with various relaxation times to lower energy states, and the states have different scattering cross sections for electrons. The end result is that the conductivity fluctuates in a random manner, and with a temperature dependence. Also, as the average DC current increases, the $1/f$ voltage noise increases since a given delta in conductivity will cause a proportionally greater change in voltage.\n",
    "\n",
    "At low temperatures, the higher energy states are not accessible, and you can be in the regime where the jumps in conductivity are easily visible. The same thing can happen if the current is flowing through a very narrow cross-section, such that a few defects can dominate the conductivity.\n",
    "\n",
    "Unlike Johnson noise, $1/f$ noise is highly dependent on the physical type of resistor or component under consideration. Annealing a metal film tends to reduce the number of defects, so $1/f$ noise is reduced. Conversely, radiation damage can create defects that lead to an increase in $1/f$ noise.\n",
    "\n",
    "$1/f$ noise occurs in something as simple as a switch contact (hence the term *switching noise*) as a result of the small cross-section where current has to flow. To reduce this effect, switches can be made with multiple contacts to increase the area.\n",
    "\n",
    "## Interesting sources of noise\n",
    "\n",
    "Physics experiments quite often have to work close to the limit of what is possible. As such, minimising noise is something that physicists are often obsessed by. Over the years we tend to accummulate \"war stories\" describing particularly tricky noise problems that we have overcome. Here are some examples:\n",
    "\n",
    "- semiconductors are sensitive to light, and so they are usually encapsulated in opaque plastic or ceramic packages. If light can somehow still reach the semiconductor, you may see soem unexpected effects, such as 100 Hz oscillation from fluorescent lamps.\n",
    "\n",
    "- mechanical vibration can cause induced currents resulting from electric fields and changing capacitances. This is sometimes referred to as \"microphonics\" since the circuit can pick up sounds waves somewhat like a microphone.\n",
    "\n",
    "- the tribolectric effect generates current when two dissimilar objects move relative to each other. This movement can be as simple as the bending of a cable consisting of a conductor and an insulator. As such, the triboelectric effect is another way for mechanical vibration to cause voltage noise.\n",
    "\n",
    "- junctions between dissimilar metals will generate a voltage through the thermoelectric effect. If the temperature is fluctuating, you will see an apparent voltage noise. While this is usually at a fairly low frequency (due to longish thermal time constants) it can be short if the volumes of metals are small. \n",
    "\n",
    "- see [this article by myself and Nic Bongham](http://mcba11.phys.unsw.edu.au/~plato-a/papers/bin14a.pdf) for how an interesting noise problem was solved.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
